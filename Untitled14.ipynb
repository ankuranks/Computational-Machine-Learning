{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.vq import vq\n",
    "\n",
    "\n",
    "class Vlad:\n",
    "\n",
    "\n",
    "    def __init__(self, clusters_centers):\n",
    "        self.clusters_centers = clusters_centers\n",
    "        self.n_clusters = clusters_centers.shape[0]\n",
    "        self.descriptors_dimension = clusters_centers.shape[1]\n",
    "\n",
    "    def get_image_vlad_matricial(self, descriptors):\n",
    "        dimension = descriptors.shape[1]\n",
    "        if dimension != self.descriptors_dimension:\n",
    "            raise ValueError(\"La dimension de los descriptores no calza con la dimension inicializada\")\n",
    "        #print(\"la dimension de los descriptores es ok\")\n",
    "        descriptors_expanded = np.tile(descriptors.T,(self.n_clusters,1,1))\n",
    "        #print(\"descriptors expanded shape: \"),\n",
    "        #print(descriptors_expanded.shape)\n",
    "        n_descriptors = descriptors.shape[0]\n",
    "        clusters_expanded = np.tile(self.clusters_centers.T,(n_descriptors,1,1))\n",
    "        clusters_expanded = clusters_expanded.swapaxes(0,2)\n",
    "        #print(\"clusters expanded shape: \"),\n",
    "        #print(clusters_expanded.shape)\n",
    "        difference_matrix = descriptors_expanded - clusters_expanded\n",
    "        distances_vector_clusters = np.sum(difference_matrix**2, axis=1)\n",
    "        #print(\"distances vectors clusters shape: \"),\n",
    "        #print(distances_vector_clusters.shape)\n",
    "\n",
    "        binary_nn_matrix = None\n",
    "        for i in range(n_descriptors):\n",
    "            column = np.zeros(self.n_clusters)\n",
    "            column[np.argmax(distances_vector_clusters[:,i])] = 1\n",
    "            if binary_nn_matrix is None:\n",
    "                binary_nn_matrix = column\n",
    "            else:\n",
    "                binary_nn_matrix = np.column_stack((binary_nn_matrix,column))\n",
    "        #print(\"binary nn shape: \"),\n",
    "        #print(binary_nn_matrix.shape)\n",
    "        binary_nn_matrix_expanded = np.tile(binary_nn_matrix,(self.descriptors_dimension,1,1)).swapaxes(0,1)\n",
    "        final_cube = binary_nn_matrix_expanded*difference_matrix\n",
    "        vlad_matrix =  np.sum(final_cube, axis=2)\n",
    "        flat_vlad = vlad_matrix.reshape((self.descriptors_dimension*self.n_clusters,))\n",
    "        return normalize(flat_vlad)\n",
    "\n",
    "    def get_image_vlad(self, descriptors):\n",
    "        binary_nn, distances = vq(descriptors,self.clusters_centers)\n",
    "        vlad = np.zeros((self.n_clusters,self.descriptors_dimension))\n",
    "        for i in range(len(descriptors)):\n",
    "            descriptor = descriptors[i]\n",
    "            nearest_cluster_index = binary_nn[i]\n",
    "            nearest_cluster = self.clusters_centers[nearest_cluster_index]\n",
    "            vlad[nearest_cluster_index] += descriptor - nearest_cluster\n",
    "        flat_vlad = vlad.reshape((self.descriptors_dimension*self.n_clusters,))\n",
    "        print(flat_vlad)\n",
    "        print('aha')\n",
    "        return normalize(flat_vlad)\n",
    "\n",
    "\n",
    "def normalize(array):\n",
    "    norm = np.linalg.norm(array)\n",
    "    print(array/norm)\n",
    "    print('Yes')\n",
    "    return array/norm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'get_descriptors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2b9481373217>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:\\Anu'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mget_descriptor_from_image_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_descriptor_from_image_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-aa932c469167>\u001b[0m in \u001b[0;36mget_descriptor_from_image_path\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mresize_to\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m640\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mgray_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCV_LOAD_IMAGE_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_descriptors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresize_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'get_descriptors'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import utils\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "path = 'C:\\Anu'\n",
    "get_descriptor_from_image_path(path)\n",
    "\n",
    "def get_descriptor_from_image_path(path):\n",
    "    resize_to = 640\n",
    "    gray_img = cv2.imread(path, cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "    return utils.get_descriptors(gray_img, resize=resize_to)\n",
    "\n",
    "\n",
    "def calculate_descriptors(img_files):\n",
    "\t''' Gets the descriptors for every image in the input. Stores them in files.\n",
    "\tArgs:\n",
    "\t\timg_files (list of string): The path for each image file in the dataset.\n",
    "\tReturns:\n",
    "\t\tint: number of descriptors.\n",
    "\t'''\n",
    "\tdescriptors = None\n",
    "\tfiles_count = len(img_files)\n",
    "\tstep = (5 * files_count) / 100\n",
    "\tmax_size = 250\n",
    "\tdescriptors_count = 0\n",
    "\tmin_desc_ind = 0\n",
    "\tmax_desc_ind = 0\n",
    "\tresize_to = 640\n",
    "\tfor i in range(files_count):\n",
    "\t\t# Get the descriptors for each grayscale image \n",
    "\t\tfilename = img_files[i]\n",
    "\t\tgray_img = cv2.imread(filename, cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "\t\tcurrent_img_des = utils.get_descriptors(gray_img, resize=resize_to)\n",
    "\t\tdescriptors_count += len(current_img_des)\n",
    "\t\tif descriptors is None:\n",
    "\t\t\tdescriptors = current_img_des\n",
    "\t\telse:\n",
    "\t\t\tdescriptors = np.vstack((descriptors, current_img_des))\n",
    "\t\tif i % step == 0:\n",
    "\t\t\tpercentage = (i * 100) / files_count\n",
    "\t\t\tprint(\n",
    "\t\t\t\t\"Getting descriptors in image number {0} of {1} ({2}%)\".format(\n",
    "\t\t\t\t\ti, files_count, percentage\n",
    "\t\t\t\t)\n",
    "\t\t\t)\n",
    "\t\t# Stores the descriptors in a file to avoid memory errors\n",
    "\t\tif i % max_size == 0 and i > 0:\n",
    "\t\t\tmax_desc_ind = descriptors_count - 1\n",
    "\t\t\tstorage_count = i / max_size\n",
    "\t\t\tstorage_name = \"des_{0}_{1}_{2}.np\".format(\n",
    "\t\t\t\tstorage_count, min_desc_ind, max_desc_ind\n",
    "\t\t\t)\n",
    "\t\t\tpickle.dump(descriptors, open(storage_name, \"wb\"), protocol=2)\n",
    "\t\t\tmin_desc_ind += len(descriptors)\n",
    "\t\t\tdescriptors = None\n",
    "\treturn descriptors_count\n",
    "\n",
    "def get_sample():\n",
    "\t# Sacar random sample de 100k\n",
    "\tdes_files = glob.glob(\"des_*\")\n",
    "\tfile_indices = [int(des_f.split(\"_\")[1]) for des_f in des_files]\n",
    "\tmax_index = 0\n",
    "\tmax_value = 0\n",
    "\tfor i in range(len(file_indices)):\n",
    "\t\tcurrent_value = file_indices[i]\n",
    "\t\tif current_value > max_value:\n",
    "\t\t\tmax_value = current_value\n",
    "\t\t\tmax_index = i\n",
    "\tlast_file = des_files[max_index]\n",
    "\tprint (\"Last file is: {0}\".format(last_file))\n",
    "\tdes_count = int(last_file.split(\".\")[0].split(\"_\")[-1])\n",
    "\tprint (\"Descriptors count is: {0}\".format(des_count))\n",
    "\tsample_indices = np.arange(des_count)\n",
    "\tsample_size = 100000\n",
    "\tnp.random.shuffle(sample_indices)\n",
    "\tsample = utils.read_des_files(sample_indices[:sample_size])\n",
    "\tpickle.dump(sample, open(\"sample.np\", \"wb\"), protocol=2)\n",
    "\tprint(\"Sample of shape: {0}\".format(sample.shape))\n",
    "\treturn sample\n",
    "\n",
    "def get_clusters(k, sample):\n",
    "\t''' Calculates the k clusters centers which are going to be the codewords\n",
    "\tfor our codebook. It only uses a random sample of 100k of the descriptors\n",
    "\tand applies the k-means clustering algorithm to them.\n",
    "\tArgs:\n",
    "\t\tk (int): The number of clusters.\n",
    "\t\tsample (numpy matrix of float32): The 100k descriptors sample.\n",
    "\tReturns:\n",
    "\t\tlist of floats array: Each array is a cluster mean vector (D = 128).\n",
    "\t'''\n",
    "\t# Clusterizar\n",
    "\tkmeans = KMeans(n_clusters=k)\n",
    "\tkmeans.fit(sample)\n",
    "\treturn kmeans.cluster_centers_\n",
    "print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

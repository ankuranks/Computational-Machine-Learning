{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(5L, 512L)\n",
      "hello\n",
      "[[-0.99643487 -0.71052133 -0.5        ..., -0.51803788 -0.68005985\n",
      "   1.77951432]\n",
      " [-1.08702261 -0.80780097 -0.5        ...,  1.95634698  0.34456186\n",
      "   0.34649812]\n",
      " [ 0.66276866  1.84876906 -0.5        ..., -0.67091654 -0.75656434\n",
      "  -0.54562704]\n",
      " [-0.1194323  -0.59538176  2.         ..., -0.10105821  1.82080684\n",
      "  -0.50144544]\n",
      " [ 1.54012111  0.26493501 -0.5        ..., -0.66633435 -0.72874452\n",
      "  -1.07893996]]\n",
      "M HERE\n",
      "[[-1.08702261 -0.80780097 -0.5        ...,  1.95634698  0.34456186\n",
      "   0.34649812]\n",
      " [ 0.66276866  1.84876906 -0.5        ..., -0.67091654 -0.75656434\n",
      "  -0.54562704]]\n",
      "vlad\n",
      "[[  259.98562414   301.46537362  -106.36974573 ...,   529.13358601\n",
      "    584.29539697   -83.45948036]\n",
      " [  955.12469007  1802.28006753  1906.73428243 ...,  1579.59553028\n",
      "   2495.56710946  2464.03463332]]\n",
      "Approximate Neighbor\n",
      "(array([[ -4.44089210e-16,   5.00823363e-01],\n",
      "       [ -2.22044605e-16,   5.00823363e-01]]), array([[0, 1],\n",
      "       [1, 0]], dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:39: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "import pandas\n",
    "import math\n",
    "import sys\n",
    "import subprocess\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from pylab import plot,show\n",
    "from numpy import vstack,array\n",
    "from numpy.random import rand\n",
    "from scipy.cluster.vq import vq\n",
    "import urllib, urlparse\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from skimage.io import imread_collection\n",
    "from skimage.feature import hog\n",
    "from skimage.io.manage_plugins import call_plugin\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import math\n",
    "from sklearn.neighbors import LSHForest as LSHForest\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "def read(bin_size = 8): \n",
    "    feature_size = math.pow(bin_size, 3)\n",
    "    path = 'C:/Anu2/'\n",
    "    imlist = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.jpg')]\n",
    "    features = np.zeros([len(imlist), feature_size])\n",
    "    #print (features)\n",
    "    for i, f in enumerate(imlist):\n",
    "        im = np.array(Image.open(f))\n",
    "        #multiple dim:\n",
    "        h, edges = np.histogramdd(im.reshape(-1, 3), bin_size, normed=True, range=[(0,255),(0,255),(0,255)])\n",
    "        features[i] = h.flatten()\n",
    "        #print features[i].shape\n",
    "    print features.shape\n",
    "    return features#.shape\n",
    "\n",
    "def createVocabulary(data,k,itr):\n",
    "    clust_centers, labels = mykmeansplusplus(data,k,itr)\n",
    "    return clust_centers\n",
    "\n",
    "def mykmeansplusplus (points,k,itr):\n",
    "    data_x_shape = points.shape[0]\n",
    "    index = np.random.randint(data_x_shape, size =1)\n",
    "    initial_clust_center = points[index]\n",
    "    initialCentroid = points[index]\n",
    "    weight = np.zeros((points.shape[0]))\n",
    "    index = np.zeros((points.shape[0]))\n",
    "\n",
    "    for i in range(0,(k - 1)):\n",
    "        Y= cdist(points, initialCentroid, metric='euclidean', p=2, V=None, VI=None, w=None)\n",
    "        min_dist = np.amin(Y, axis=1) \n",
    "        min_center = np.argmin(Y, axis=1)\n",
    "        min_dist_sum = np.sum(min_dist, axis=0)\n",
    "        min_squared_dist_sum = np.sum(min_dist**2, axis=0)\n",
    "        min_dist = min_dist**2\n",
    "        min_dist_prob = min_dist / min_squared_dist_sum\n",
    "        next_index = np.random.choice(points.shape[0],1,p=min_dist_prob)\n",
    "        initial_clust_center = np.concatenate((initial_clust_center,points[next_index]),axis=0)\n",
    "        \n",
    "    initial_class = np.zeros((points.shape[0]))\n",
    "    for j in range(0,itr):\n",
    "        Z=cdist(points, initial_clust_center, metric='euclidean', p=2, V=None, VI=None, w=None)\n",
    "        target_dist = np.amin(Z, axis=1)  \n",
    "        target_class = np.argmin(Z, axis=1)\n",
    "        for i in range(0,k-1):\n",
    "            values = points[target_class == i]\n",
    "            #print(values)\n",
    "            #print(i)\n",
    "            initialCentroid[i,:] = np.mean(values, axis = 0)\n",
    "        if np.array_equal(initial_class,target_class):\n",
    "            break\n",
    "        else:\n",
    "            initial_class = target_class\n",
    "\n",
    "    return initial_clust_center, target_class  \n",
    "\n",
    "def my_vlad(local_descriptors, centroids):\n",
    "    V = np.zeros([centroids.shape[0],local_descriptors.shape[1]])\n",
    "    distances = pairwise_distances(local_descriptors, centroids, metric='euclidean')\n",
    "    clusters = np.argmin(distances,axis=1)\n",
    "    for iter, center in enumerate(centroids):\n",
    "        points_belonging_to_cluster = local_descriptors[clusters == iter]\n",
    "        V[iter] = np.sum(points_belonging_to_cluster - center, axis=0)\n",
    "        \n",
    "    return V\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "print ('1')\n",
    "content = read(8)\n",
    "#print content\n",
    "print('hello')\n",
    "content = preprocessing.scale(content,axis = 0, with_mean=True, with_std=True)\n",
    "print content\n",
    "print(\"M HERE\")\n",
    "centroids = createVocabulary(content,2,100)\n",
    "print centroids\n",
    "#centroids=getvlad(centroids)\n",
    "X_train,y_train = make_blobs(n_samples=500, n_features=512, centers=2)\n",
    "#X_train= load_iris()\n",
    "#X_train,y_train = make_distance(n_samples=500, n_features=512, centers=2)\n",
    "#X_train,y_train = \n",
    "vlad = my_vlad(X_train, centroids)\n",
    "#print(centroids)\n",
    "print(\"vlad\")\n",
    "print vlad\n",
    "lshf = LSHForest(random_state=42)\n",
    "lshf.fit(vlad) \n",
    "print(\"Approximate Neighbor\")\n",
    "approx_neighbors = lshf.kneighbors(vlad,4,return_distance=True)\n",
    "print approx_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

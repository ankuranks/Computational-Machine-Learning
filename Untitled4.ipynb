{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "import pandas\n",
    "import math\n",
    "import sys\n",
    "import subprocess\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from pylab import plot,show\n",
    "from numpy import vstack,array\n",
    "from numpy.random import rand\n",
    "from scipy.cluster.vq import vq\n",
    "import urllib, urlparse\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def load():\n",
    "    loc = 'C:/Anu';\n",
    "    content = np.zeros((1,128)) \n",
    "    content = np.matrix(content)\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for a in listdir(loc):\n",
    "        y = y + 1\n",
    "        if y % 10  == 0:\n",
    "            if isfile(join(loc,a)):\n",
    "                with open(join(loc,a)) as b:\n",
    "                    for li in b:\n",
    "                        if not li.isspace():\n",
    "                            des = map(float, li.split())                            \n",
    "                            des = np.asarray(des)                          \n",
    "                            descriptor = np.matrix(des)                           \n",
    "                            descriptor = np.asarray(descriptor)                            \n",
    "                            if x > 0:\n",
    "                                content = np.concatenate((content,descriptor),axis=0)\n",
    "                            else:\n",
    "                                content[x,:] = descriptor                          \n",
    "                            x += 1\n",
    "    return content\n",
    "    \n",
    "def mykmeansplusplus (points,k,itr):\n",
    "    data_x_shape = points.shape[0]\n",
    "    index = np.random.randint(data_x_shape, size =1)\n",
    "    initialCentroid = points[index]\n",
    "    weight = np.zeros((points.shape[0]))\n",
    "    index = np.zeros((points.shape[0]))\n",
    "\n",
    "    for i in range(0,(k - 1)):\n",
    "        Y= cdist(points, initialCentroid, metric='euclidean', p=2, V=None, VI=None, w=None)\n",
    "        min_dist = np.amin(Y, axis=1) \n",
    "        min_center = np.argmin(Y, axis=1)\n",
    "        min_dist_sum = np.sum(min_dist, axis=0)\n",
    "        min_squared_dist_sum = np.sum(min_dist**2, axis=0)\n",
    "        min_dist = min_dist**2\n",
    "        min_dist_prob = min_dist / min_squared_dist_sum\n",
    "        next_index = np.random.choice(points.shape[0],1,p=min_dist_prob)\n",
    "        initial_clust_center = np.concatenate((initial_clust_center,points[next_index]),axis=0)\n",
    "        \n",
    "    initial_class = np.zeros((points.shape[0]))\n",
    "    for j in range(0,max_iter):\n",
    "        Z=tapoints, initial_clust_center, metric='euclidean', p=2, V=None, VI=None, w=None)\n",
    "        target_dist = np.amin(Z, axis=1)  \n",
    "        target_class = np.argmin(Z, axis=1)\n",
    "        for i in range(0,n_cluster):\n",
    "            values = points[target_class == i]\n",
    "            initialCentroid[i,:] = np.mean(values, axis = 0)\n",
    "        if np.array_equal(initial_class,target_class):\n",
    "            break\n",
    "        else:\n",
    "            initial_class = target_class\n",
    "\n",
    "    return initial_clust_center, target_class  \n",
    "        \n",
    "\n",
    "def createVocabulary(data,k,itr):\n",
    "    clust_centers, labels = mykmeansplusplus(data,k,itr)\n",
    "    return clust_centers\n",
    "\n",
    " def getvlad( clusters):\n",
    "        binary_nn, distances = vq(clusters)\n",
    "        vlad = np.zeros((3,128))\n",
    "        for i in range(len(clusters)):\n",
    "            clusters = clusters[i]\n",
    "            nearest_cluster_index = binary_nn[i]\n",
    "            nearest_cluster = self.clusters_centers[nearest_cluster_index]\n",
    "            vlad[nearest_cluster_index] += clusters - nearest_cluster\n",
    "        flat_vlad = vlad.reshape((self.descriptors_dimension*self.n_clusters,))\n",
    "        print(flat_vlad)\n",
    "        print('Vlad generated')\n",
    "        return normalize(flat_vlad)\n",
    "\n",
    "    \n",
    "content = load()\n",
    "#Normalise\n",
    "content = preprocessing.scale(content,axis = 0, with_mean=True, with_std=True)\n",
    "#Create Vocabulary with the images extracted\n",
    "centroids = createVocabulary(content,10,100)\n",
    "#Implement VLAD on the clusters generated \n",
    "\n",
    "centroids=getvlad(centroids)\n",
    "\n",
    "approx_neighbors = lshf.kneighbors(centroids, return_distance=False)\n",
    "\n",
    "#neigh.fit(f_vector, fvector1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Vocab\n",
      "[[ 0.32729048  0.05068629  0.00285477 ...,  0.          0.          0.00745253]\n",
      " [ 0.24566458  0.11229488  0.08108898 ...,  0.00097889  0.05895923\n",
      "   0.56247044]]\n",
      "Now Make VLAD\n",
      "[[  -0.96628315    0.54264974    1.20020293 ...,    0.92741116\n",
      "     2.73038891    5.48059966]\n",
      " [ -45.609509    -43.74196735  -38.58202637 ...,    0.68326428\n",
      "   -11.66506102 -171.76473985]]\n",
      "After VLAD\n",
      "Applying ANN Now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:89: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial.distance import euclidean\n",
    "import math\n",
    "import os\n",
    "\n",
    "class RGBHistogram:\n",
    "\tdef __init__(self, bins):\n",
    "\t\t# store the number of bins the histogram will use\n",
    "\t\tself.bins = bins\n",
    " \n",
    "\tdef describe(self, image):\n",
    "\t\thist = cv2.calcHist([image], [0, 1, 2],\n",
    "\t\t\tNone, self.bins, [0, 256, 0, 256, 0, 256])\n",
    "\t\thist = cv2.normalize(hist)\n",
    "\n",
    "\t\treturn hist.flatten()\n",
    "\n",
    "    \n",
    "# import the necessary packages\n",
    "#from pyimagesearch.rgbhistogram import RGBHistogram\n",
    "import argparse\n",
    "import cPickle\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.neighbors import LSHForest as LSHForest\n",
    "from sklearn.neighbors import LSHForest\n",
    "\n",
    "#initialize the index dictionary to store our our quantifed\n",
    "# images, with the 'key' of the dictionary being the image\n",
    "# filename and the 'value' our computed features\n",
    "index = {}\n",
    "\n",
    "def createVocabulary(data,k,itr):\n",
    "    clust_centers, labels = mykmeansplusplus(data,k,itr)\n",
    "    f = open(\"C:/Index-Project/ankur.txt\", \"w\")\n",
    "    f.write(cPickle.dumps(index))\n",
    "    f.close()\n",
    "    return clust_centers\n",
    "\n",
    "def mykmeansplusplus (points,k,itr):\n",
    "    data_x_shape = points.shape[0]\n",
    "    index = np.random.randint(data_x_shape, size =1)\n",
    "    initial_clust_center = points[index]\n",
    "    initialCentroid = points[index]\n",
    "    weight = np.zeros((points.shape[0]))\n",
    "    index = np.zeros((points.shape[0]))\n",
    "\n",
    "    for i in range(0,(k - 1)):\n",
    "        Y= cdist(points, initialCentroid, metric='euclidean', p=2, V=None, VI=None, w=None)\n",
    "        min_dist = np.amin(Y, axis=1) \n",
    "        min_center = np.argmin(Y, axis=1)\n",
    "        min_dist_sum = np.sum(min_dist, axis=0)\n",
    "        min_squared_dist_sum = np.sum(min_dist**2, axis=0)\n",
    "        min_dist = min_dist**2\n",
    "        min_dist_prob = min_dist / min_squared_dist_sum\n",
    "        next_index = np.random.choice(points.shape[0],1,p=min_dist_prob)\n",
    "        initial_clust_center = np.concatenate((initial_clust_center,points[next_index]),axis=0)\n",
    "        \n",
    "    initial_class = np.zeros((points.shape[0]))\n",
    "    for j in range(0,itr):\n",
    "        Z=cdist(points, initial_clust_center, metric='euclidean', p=2, V=None, VI=None, w=None)\n",
    "        target_dist = np.amin(Z, axis=1)  \n",
    "        target_class = np.argmin(Z, axis=1)\n",
    "        for i in range(0,k-1):\n",
    "            values = points[target_class == i]\n",
    "            #print(values)\n",
    "            #print(i)\n",
    "            initialCentroid[i,:] = np.mean(values, axis = 0)\n",
    "        if np.array_equal(initial_class,target_class):\n",
    "            break\n",
    "        else:\n",
    "            initial_class = target_class\n",
    "\n",
    "    return initial_clust_center, target_class  \n",
    "\n",
    "# initialize our image descriptor -- a 3D RGB histogram with\n",
    "# 8 bins per channel\n",
    "desc = RGBHistogram([8, 8, 8])\n",
    "feature_size = math.pow(8, 3)\n",
    "def read():\n",
    "    path = 'C:/Anu/'\n",
    "    imlist = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.jpg')]\n",
    "    featuresCollect = np.zeros([len(imlist), feature_size])\n",
    "    i=0\n",
    "    # use glob to grab the image paths and loop over them\n",
    "    for imagePath in glob.glob(\"C:/Anu\" + \"/*.jpg\"):\n",
    "        # extract our unique image ID (i.e. the filename)\n",
    "        k = imagePath[imagePath.rfind(\"/\") + 1:]\n",
    "        # load the image, describe it using our RGB histogram\n",
    "        # descriptor, and update the index\n",
    "        image = cv2.imread(imagePath)\n",
    "        features = desc.describe(image)\n",
    "        preprocessing.scale(features,axis = 0, with_mean=True, with_std=False)\n",
    "        featuresCollect[i] = features \n",
    "        i=i+1\n",
    "        index[k] = features\n",
    "    \n",
    "\n",
    "    \n",
    "print \"Time taken by read\"\n",
    "t0 = time.time()\n",
    "read()\n",
    "print (time.time()-t0)\n",
    "\n",
    "clusters = createVocabulary(featuresCollect,2,100)\n",
    "print \"Done with Vocab\"\n",
    "print vocab    \n",
    "\n",
    "def myvlad(local_descriptors, centroids):\n",
    "    V = np.zeros([centroids.shape[0],local_descriptors.shape[1]])\n",
    "    distances = pairwise_distances(local_descriptors, centroids, metric='euclidean')\n",
    "    clusters = np.argmin(distances,axis=1)\n",
    "    for iter, center in enumerate(centroids):\n",
    "        points_belonging_to_cluster = local_descriptors[clusters == iter]\n",
    "        V[iter] = np.sum(points_belonging_to_cluster - center, axis=0)\n",
    "        \n",
    "    return V\n",
    "\n",
    "print \"Now Make VLAD\"\n",
    "#vlad = my_vlad(featuresCollect,vocab)\n",
    "print vlad\n",
    "print \"After VLAD\"\n",
    "\n",
    "print \"Applying ANN Now\"\n",
    "\n",
    "#approx_neighbors = lshf.kneighbors(vlad,4,return_distance=True)\n",
    "#print approx_neighbors\n",
    "    \n",
    "# we are now done indexing our image -- now we can write our\n",
    "# index to disk\n",
    "\n",
    "\n",
    "\n",
    "# import the necessary packages\n",
    "import numpy as np\n",
    " \n",
    "class VLAD:\n",
    "\tdef __init__(self, index):\n",
    "\t\t# store our index of images\n",
    "\t\tself.index = index\n",
    " \n",
    "\tdef my_vlad(self, queryFeatures):\n",
    "\t\t# initialize our dictionary of results\n",
    "\t\tresults = {}\n",
    " \n",
    "\t\t# loop over the index\n",
    "\t\tfor (k, features) in self.index.items():\n",
    "\t\t\t# compute the chi-squared distance between the features\n",
    "\t\t\t# in our index and our query features -- using the\n",
    "\t\t\t# chi-squared distance which is normally used in the\n",
    "\t\t\t# computer vision field to compare histograms\n",
    "\t\t\td = self.chi2_distance(features, queryFeatures)\n",
    " \n",
    "\t\t\t# now that we have the distance between the two feature\n",
    "\t\t\t# vectors, we can udpate the results dictionary -- the\n",
    "\t\t\t# key is the current image ID in the index and the\n",
    "\t\t\t# value is the distance we just computed, representing\n",
    "\t\t\t# how 'similar' the image in the index is to our query\n",
    "\t\t\tresults[k] = d\n",
    " \n",
    "\t\t# sort our results, so that the smaller distances (i.e. the\n",
    "\t\t# more relevant images are at the front of the list)\n",
    "\t\tresults = sorted([(v, k) for (k, v) in results.items()])\n",
    " \n",
    "\t\t# return our results\n",
    "\t\treturn results\n",
    " \n",
    "\tdef chi2_distance(self, histA, histB, eps = 1e-10):\n",
    "\t\t# compute the chi-squared distance\n",
    "\t\td = 0.5 * np.sum([((a - b) ** 2) / (a + b + eps)\n",
    "\t\t\tfor (a, b) in zip(histA, histB)])\n",
    " \n",
    "\t\t# return the chi-squared distance\n",
    "\t\treturn d\n",
    "    \n",
    "# def my_ANN(X):\n",
    "#        lshf = LSHForest(n_estimators=20, n_candidates=200,n_neighbors=10).fit(X))\n",
    "#        approx_neighbors = lshf.kneighbors(query, return_distance=False)\n",
    "#        return approx_neighbors\n",
    "    \n",
    "\n",
    "# import the necessary packages\n",
    "#from pyimagesearch.searcher import Searcher\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cPickle\n",
    "import cv2\n",
    "\n",
    "# load the index and initialize our searcher\n",
    "index = cPickle.loads(open(\"C:/Index-Project/ankur.txt\").read())\n",
    "searcher = VLAD(index)\n",
    "\n",
    "\n",
    "# loop over images in the index -- we will use each one as\n",
    "# a query image\n",
    "cv2.startWindowThread()\n",
    "#for (query, queryFeatures) in index.items():\n",
    "# perform the search using the current query\n",
    "query=\"131500.jpg\"\n",
    "path =\"C:/\" + \"/Anu/%s\" % (query)\n",
    "#print path\n",
    "image = cv2.imread(path)\n",
    "#print image\n",
    "queryFeatures = desc.describe(image)\n",
    "results = searcher.my_vlad(queryFeatures)\n",
    " \n",
    "# load the query image and display itqueryFeatures\n",
    "#print query\n",
    "#print queryFeatures\n",
    "\n",
    "#print path\n",
    "queryImage = cv2.imread(path)\n",
    "#print queryImage\n",
    "#print queryImage\n",
    "cv2.imshow('Query', queryImage)\n",
    "cv2.waitKey(0) & 0xFF\n",
    "#print \"query: %s\" % (query)\n",
    " \n",
    "# initialize the two montages to display our results --\n",
    "# we have a total of 25 images in the index, but let's only\n",
    "# display the top 10 results; 5 images per montage, with\n",
    "# images that are 400x166 pixels\n",
    "montageA = np.zeros((3264*5,2448,3), dtype = \"uint8\")\n",
    "#montageB = np.zeros((3264*5,2448,3), dtype = \"uint8\")\n",
    "\n",
    "# loop over the top ten results\n",
    "for j in xrange(0, 5):\n",
    "\t# grab the result (we are using row-major order) and\n",
    "\t# load the result image\n",
    "\t(score, imageName) = results[j]\n",
    "\t#print imageName\n",
    "\tpath = \"C:/\" + \"/%s\" % (imageName)\n",
    "\tresult = cv2.imread(path)\n",
    "\tcv2.imshow(\"Results 1-5\", result)\n",
    "\tcv2.waitKey(0) & 0xFF\n",
    "\n",
    "cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "(512L,)\n",
      "(512L,)\n",
      "(512L,)\n",
      "(512L,)\n",
      "(512L,)\n",
      "(512L,)\n",
      "(6L, 512L)\n",
      "(6L, 512L)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:58: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "import pandas\n",
    "import math\n",
    "import sys\n",
    "import subprocess\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from pylab import plot,show\n",
    "from numpy import vstack,array\n",
    "from numpy.random import rand\n",
    "from scipy.cluster.vq import vq\n",
    "import urllib, urlparse\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from skimage.io import imread_collection\n",
    "from skimage.feature import hog\n",
    "from skimage.io.manage_plugins import call_plugin\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "def load():\n",
    "    loc = 'C:/Anu';\n",
    "    content = np.zeros((1,128)) \n",
    "    content = np.matrix(content)\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for a in listdir(loc):\n",
    "        y = y + 1\n",
    "        if isfile(join(loc,a)):\n",
    "            with open(join(loc,a)) as b:\n",
    "                for li in b:\n",
    "                    if not li.isspace():\n",
    "                        des = map(float, li.split())                            \n",
    "                        des = np.asarray(des)                          \n",
    "                        descriptor = np.matrix(des)                           \n",
    "                        descriptor = np.asarray(descriptor)                            \n",
    "                        if x > 0:\n",
    "                            content = np.concatenate((content,descriptor),axis=0)\n",
    "                        else:\n",
    "                            content[x,:] = descriptor                          \n",
    "                        x += 1\n",
    "    return content\n",
    "\n",
    "def read(bin_size = 8): \n",
    "    feature_size = math.pow(bin_size, 3)\n",
    "    path = 'C:/Anu/'\n",
    "    imlist = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.jpg')]\n",
    "    features = np.zeros([len(imlist), feature_size])\n",
    "    print (features)\n",
    "    for i, f in enumerate(imlist):\n",
    "        im = np.array(Image.open(f))\n",
    "        #multiple dim:\n",
    "        h, edges = np.histogramdd(im.reshape(-1, 3), bin_size, normed=True, range=[(0,255),(0,255),(0,255)])\n",
    "        features[i] = h.flatten()\n",
    "        print features[i].shape\n",
    "    print features.shape\n",
    "    return features.shape\n",
    "\n",
    "content = read(8)\n",
    "\n",
    "print content\n",
    "\n",
    "#pick a number of bin size for pic representation \n",
    "# EX: bin_size = 8  pic's vector = (8 * 8 * 8) in three dim\n",
    "# normed=True within np.histogramdd() deal with different image size\n",
    "\n",
    "def mykmeansplusplus (points,k,itr):\n",
    "    data_x_shape = points.shape[0]\n",
    "    index = np.random.randint(data_x_shape, size =1)\n",
    "    initialCentroid = points[index]\n",
    "    weight = np.zeros((points.shape[0]))\n",
    "    index = np.zeros((points.shape[0]))\n",
    "\n",
    "    for i in range(0,(k - 1)):\n",
    "        Y= cdist(points, initialCentroid, metric='euclidean', p=2, V=None, VI=None, w=None)\n",
    "        min_dist = np.amin(Y, axis=1) \n",
    "        min_center = np.argmin(Y, axis=1)\n",
    "        min_dist_sum = np.sum(min_dist, axis=0)\n",
    "        min_squared_dist_sum = np.sum(min_dist**2, axis=0)\n",
    "        min_dist = min_dist**2\n",
    "        min_dist_prob = min_dist / min_squared_dist_sum\n",
    "        next_index = np.random.choice(points.shape[0],1,p=min_dist_prob)\n",
    "        initial_clust_center = np.concatenate((initial_clust_center,points[next_index]),axis=0)    \n",
    "    initial_class = np.zeros((points.shape[0]))\n",
    "    for j in range(0,max_iter):\n",
    "        Z=cdist(tapoints, initial_clust_center, metric='euclidean', p=2, V=None, VI=None, w=None)\n",
    "        target_dist = np.amin(Z, axis=1)  \n",
    "        target_class = np.argmin(Z, axis=1)\n",
    "        for i in range(0,n_cluster):\n",
    "            values = points[target_class == i]\n",
    "            initialCentroid[i,:] = np.mean(values, axis = 0)\n",
    "        if np.array_equal(initial_class,target_class):\n",
    "            break\n",
    "        else:\n",
    "            initial_class = target_class\n",
    "\n",
    "    return initial_clust_center, target_class  \n",
    "        \n",
    "\n",
    "def createVocabulary(data,k,itr):\n",
    "    clust_centers, labels = mykmeansplusplus(data,k,itr)\n",
    "    return clust_centers\n",
    "\n",
    "def getvlad( clusters):\n",
    "    binary_nn, distances = vq(clusters)\n",
    "    vlad = np.zeros((3,128))\n",
    "    for i in range(len(clusters)):\n",
    "        clusters = clusters[i]\n",
    "        nearest_cluster_index = binary_nn[i]\n",
    "        nearest_cluster = self.clusters_centers[nearest_cluster_index]\n",
    "        vlad[nearest_cluster_index] += clusters - nearest_cluster\n",
    "    flat_vlad = vlad.reshape((self.descriptors_dimension*self.n_clusters,))\n",
    "    print(flat_vlad)\n",
    "    print('Vlad generated')\n",
    "    return normalize(flat_vlad)\n",
    "\n",
    "#content = load()\n",
    "#content = loadagain()\n",
    "\n",
    "#print content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 13] Permission denied: 'C:/Anu/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7b1e08e26de7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mf100_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/Anu/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf100_features\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 13] Permission denied: 'C:/Anu/'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "import cProfile\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "f100_features = 'C:/Anu/'\n",
    "data = np.zeros((128))\n",
    "with open(f100_features) as f:           \n",
    "    i = 0\n",
    "    for line in f:\n",
    "        floats = map(float, line.split())\n",
    "        floats = np.asarray(floats)\n",
    "        float1 = np.matrix(floats)\n",
    "        float1 = np.asarray(float1)\n",
    "        if(i == 0):\n",
    "            data = float1\n",
    "        else:\n",
    "            data = np.concatenate((data,float1),axis = 0)\n",
    "        i = i + 1 \n",
    "        \n",
    "pca = PCA()\n",
    "pca.fit(data)\n",
    "print(pca.explained_variance_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by read\n",
      "0.0\n",
      "Done with Vocab\n",
      "Now Make VLAD\n",
      "After VLAD\n",
      "Applying ANN Now\n",
      "Time taken by vlad\n",
      "1.33700013161\n",
      "Testing path\n",
      "C://Anu\\131301.jpg\n",
      "Testing path\n",
      "C://Anu\\146206.jpg\n",
      "Testing path\n",
      "C://Anu\\131603.jpg\n",
      "Testing path\n",
      "C://Anu\\131602.jpg\n",
      "Testing path\n",
      "C://Anu\\141303.jpg\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps of the chain should be transforms and implement fit and transform '<__main__.VLAD instance at 0x000000001ED38B08>' (type <type 'instance'>) doesn't)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d822e081d15b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m \u001b[0mvlad_pipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'myown'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyVlad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'vlad_pca'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'vlad_scaling'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'svm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[0mnum_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, steps)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 raise TypeError(\"All intermediate steps of the chain should \"\n\u001b[0;32m     89\u001b[0m                                 \u001b[1;34m\"be transforms and implement fit and transform\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                                 \" '%s' (type %s) doesn't)\" % (t, type(t)))\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: All intermediate steps of the chain should be transforms and implement fit and transform '<__main__.VLAD instance at 0x000000001ED38B08>' (type <type 'instance'>) doesn't)"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial.distance import euclidean\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "class RGBHistogram:\n",
    "\tdef __init__(self, bins):\n",
    "\t\t# store the number of bins the histogram will use\n",
    "\t\tself.bins = bins\n",
    " \n",
    "\tdef describe(self, image):\n",
    "\t\thist = cv2.calcHist([image], [0, 1, 2],\n",
    "\t\t\tNone, self.bins, [0, 256, 0, 256, 0, 256])\n",
    "\t\thist = cv2.normalize(hist)\n",
    "\n",
    "\t\treturn hist.flatten()\n",
    "\n",
    "    \n",
    "# import the necessary packages\n",
    "#from pyimagesearch.rgbhistogram import RGBHistogram\n",
    "import argparse\n",
    "import cPickle\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.neighbors import LSHForest as LSHForest\n",
    "\n",
    "#initialize the index dictionary to store our our quantifed\n",
    "# images, with the 'key' of the dictionary being the image\n",
    "# filename and the 'value' our computed features\n",
    "index = {}\n",
    "\n",
    "def createVocabulary(data,k,itr):\n",
    "    clust_centers, labels = mykmeansplusplus(data,k,itr)\n",
    "    f = open(\"C:/Index-Project/ankur.txt\", \"w\")\n",
    "    f.write(cPickle.dumps(index))\n",
    "    f.close()\n",
    "    return clust_centers\n",
    "\n",
    "def mykmeansplusplus (points,k,itr):\n",
    "    data_x_shape = points.shape[0]\n",
    "    index = np.random.randint(data_x_shape, size =1)\n",
    "    initial_clust_center = points[index]\n",
    "    initialCentroid = points[index]\n",
    "    weight = np.zeros((points.shape[0]))\n",
    "    index = np.zeros((points.shape[0]))\n",
    "\n",
    "    for i in range(0,(k - 1)):\n",
    "        Y= cdist(points, initialCentroid, metric='euclidean', p=2, V=None, VI=None, w=None)\n",
    "        min_dist = np.amin(Y, axis=1) \n",
    "        min_center = np.argmin(Y, axis=1)\n",
    "        min_dist_sum = np.sum(min_dist, axis=0)\n",
    "        min_squared_dist_sum = np.sum(min_dist**2, axis=0)\n",
    "        min_dist = min_dist**2\n",
    "        min_dist_prob = min_dist / min_squared_dist_sum\n",
    "        next_index = np.random.choice(points.shape[0],1,p=min_dist_prob)\n",
    "        initial_clust_center = np.concatenate((initial_clust_center,points[next_index]),axis=0)\n",
    "        \n",
    "    initial_class = np.zeros((points.shape[0]))\n",
    "    for j in range(0,itr):\n",
    "        Z=cdist(points, initial_clust_center, metric='euclidean', p=2, V=None, VI=None, w=None)\n",
    "        target_dist = np.amin(Z, axis=1)  \n",
    "        target_class = np.argmin(Z, axis=1)\n",
    "        for i in range(0,k-1):\n",
    "            values = points[target_class == i]\n",
    "            #print(values)\n",
    "            #print(i)\n",
    "            initialCentroid[i,:] = np.mean(values, axis = 0)\n",
    "        if np.array_equal(initial_class,target_class):\n",
    "            break\n",
    "        else:\n",
    "            initial_class = target_class\n",
    "\n",
    "    return initial_clust_center, target_class  \n",
    "\n",
    "# initialize our image descriptor -- a 3D RGB histogram with\n",
    "# 8 bins per channel\n",
    "desc = RGBHistogram([8, 8, 8])\n",
    "feature_size = math.pow(8, 3)\n",
    "def read():\n",
    "    path = \"C:/Anu/\"\n",
    "    imlist = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.jpg')]\n",
    "    featuresCollect = np.zeros([len(imlist), feature_size])\n",
    "    i=0\n",
    "    # use glob to grab the image paths and loop over them\n",
    "    for imagePath in glob.glob(\"C:/Anu\" + \"/*.jpg\"):\n",
    "        # extract our unique image ID (i.e. the filename)\n",
    "        k = imagePath[imagePath.rfind(\"/\") + 1:]\n",
    "        # load the image, describe it using our RGB histogram\n",
    "        # descriptor, and update the index\n",
    "        image = cv2.imread(imagePath)\n",
    "        features = desc.describe(image)\n",
    "        preprocessing.scale(features,axis = 0, with_mean=True, with_std=False)\n",
    "        featuresCollect[i] = features \n",
    "        i=i+1\n",
    "        index[k] = features\n",
    "    clusters = createVocabulary(featuresCollect,2,100)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "print \"Time taken by read\"\n",
    "t0 = time.time()\n",
    "#read()\n",
    "print (time.time()-t0)\n",
    "    \n",
    "print \"Done with Vocab\"\n",
    "#print vocab    \n",
    "\n",
    "def myvlad(local_descriptors, centroids):\n",
    "    V = np.zeros([centroids.shape[0],local_descriptors.shape[1]])\n",
    "    distances = pairwise_distances(local_descriptors, centroids, metric='euclidean')\n",
    "    clusters = np.argmin(distances,axis=1)\n",
    "    for iter, center in enumerate(centroids):\n",
    "        points_belonging_to_cluster = local_descriptors[clusters == iter]\n",
    "        V[iter] = np.sum(points_belonging_to_cluster - center, axis=0)\n",
    "        \n",
    "    return V\n",
    "\n",
    "print \"Now Make VLAD\"\n",
    "#vlad = my_vlad(featuresCollect,vocab)\n",
    "#print vlad\n",
    "print \"After VLAD\"\n",
    "\n",
    "print \"Applying ANN Now\"\n",
    "\n",
    "#approx_neighbors = lshf.kneighbors(vlad,4,return_distance=True)\n",
    "#print approx_neighbors\n",
    "    \n",
    "# we are now done indexing our image -- now we can write our\n",
    "# index to disk\n",
    "\n",
    "\n",
    "\n",
    "# import the necessary packages\n",
    "import numpy as np\n",
    " \n",
    "class VLAD:\n",
    "\tdef __init__(self, index):\n",
    "\t\t# store our index of images\n",
    "\t\tself.index = index\n",
    " \n",
    "\tdef my_vlad(self, queryFeatures):\n",
    "\t\t# initialize our dictionary of results\n",
    "\t\tresults = {}\n",
    " \n",
    "\t\t# loop over the index\n",
    "\t\tfor (k, features) in self.index.items():\n",
    "\t\t\t# compute the chi-squared distance between the features\n",
    "\t\t\t# in our index and our query features -- using the\n",
    "\t\t\t# chi-squared distance which is normally used in the\n",
    "\t\t\t# computer vision field to compare histograms\n",
    "\t\t\td = self.chi2_distance(features, queryFeatures)\n",
    " \n",
    "\t\t\t# now that we have the distance between the two feature\n",
    "\t\t\t# vectors, we can udpate the results dictionary -- the\n",
    "\t\t\t# key is the current image ID in the index and the\n",
    "\t\t\t# value is the distance we just computed, representing\n",
    "\t\t\t# how 'similar' the image in the index is to our query\n",
    "\t\t\tresults[k] = d\n",
    " \n",
    "\t\t# sort our results, so that the smaller distances (i.e. the\n",
    "\t\t# more relevant images are at the front of the list)\n",
    "\t\tresults = sorted([(v, k) for (k, v) in results.items()])\n",
    " \n",
    "\t\t# return our results\n",
    "\t\treturn results\n",
    " \n",
    "\tdef chi2_distance(self, histA, histB, eps = 1e-10):\n",
    "\t\t# compute the chi-squared distance\n",
    "\t\td = 0.5 * np.sum([((a - b) ** 2) / (a + b + eps)\n",
    "\t\t\tfor (a, b) in zip(histA, histB)])\n",
    " \n",
    "\t\t# return the chi-squared distance\n",
    "\t\treturn d\n",
    "    \n",
    "\n",
    "# import the necessary packages\n",
    "#from pyimagesearch.searcher import Searcher\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cPickle\n",
    "import cv2\n",
    "\n",
    "# load the index and initialize our searcher\n",
    "index = cPickle.loads(open(\"C:/Index-Project/ankur.txt\").read())\n",
    "searcher = VLAD(index)\n",
    "\n",
    "\n",
    "# loop over images in the index -- we will use each one as\n",
    "# a query image\n",
    "cv2.startWindowThread()\n",
    "#for (query, queryFeatures) in index.items():\n",
    "# perform the search using the current query\n",
    "print \"Time taken by vlad\"\n",
    "t0 = time.time()\n",
    "\n",
    "query=\"131301.jpg\"\n",
    "path =\"C:/\" + \"/Anu/%s\" % (query)\n",
    "#print path\n",
    "image = cv2.imread(path)\n",
    "#print image\n",
    "queryFeatures = desc.describe(image)\n",
    "\n",
    "results = searcher.my_vlad(queryFeatures)\n",
    "\n",
    "print (time.time()-t0)\n",
    " \n",
    "# load the query image and display itqueryFeatures\n",
    "#print query\n",
    "#print queryFeatures\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from vlad import Vlad\n",
    "#print path\n",
    "queryImage = cv2.imread(path)\n",
    "#print queryImage\n",
    "#print queryImage\n",
    "cv2.imshow('Query', queryImage)\n",
    "cv2.waitKey(0) & 0xFF\n",
    "#print \"query: %s\" % (query)\n",
    " \n",
    "# initialize the two montages to display our results --\n",
    "# we have a total of 25 images in the index, but let's only\n",
    "# display the top 10 results; 5 images per montage, with\n",
    "# images that are 400x166 pixels\n",
    "montageA = np.zeros((3264*5,2448,3), dtype = \"uint8\")\n",
    "#montageB = np.zeros((3264*5,2448,3), dtype = \"uint8\")\n",
    "\n",
    "# loop over the top ten results\n",
    "for j in xrange(0, 5):\n",
    "\t# grab the result (we are using row-major order) and\n",
    "\t# load the result image\n",
    "\t(score, imageName) = results[j]\n",
    "\t#print imageName\n",
    "\tpath = \"C:/\" + \"/%s\" % (imageName)\n",
    "\tprint \"Testing path\"\n",
    "\tprint path\n",
    "\tresult = cv2.imread(path)\n",
    "\tcv2.imshow(\"Results 1-5\", result)\n",
    "\tcv2.waitKey(0) & 0xFF\n",
    "\n",
    "cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "X =  np.concatenate([features for (k, features) in cPickle.loads(open(\"C:/Index-Project/ankur.txt\").read()).items() ])\n",
    "y =  ([k for (k, features) in cPickle.loads(open(\"C:/Index-Project/ankur.txt\").read()).items() ])\n",
    "\n",
    "X_test = np.concatenate([features for (k, features) in cPickle.loads(open(\"C:/Index-Project/ankur.txt\").read()).items() ])\n",
    "y_test =(k for (k, features) in cPickle.loads(open(\"C:/Index-Project/ankur.txt\").read()).items() )\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "myVlad = VLAD(index)\n",
    "pca = PCA(n_components=0.9)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "vlad_pipeline = Pipeline([('myown', myVlad), ('vlad_pca', pca), ('vlad_scaling', scaler), ('svm', clf)])\n",
    "\n",
    "num_clusters = [2**5]\n",
    "estimator = GridSearchCV(vlad_pipeline, dict(myown__num_clusters=num_clusters))\n",
    "estimator.fit(X,y)\n",
    "estimator.predict(X_test)\n",
    "\n",
    "score = estimator.score(X_test, y_test)\n",
    "predictions = estimator.predict(X_test)\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
